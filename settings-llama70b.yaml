# 42.5GB model file
server:
  env_name: ${APP_ENV:local}

llm:
  mode: llamacpp
  # Should be matching the selected model
  max_new_tokens: 1024
  context_window: 30000
#  tokenizer: lmstudio-community/Meta-Llama-3.1-70B-Instruct-GGUF
  prompt_style: "llama3"

llamacpp:
  llm_hf_repo_id: lmstudio-community/Meta-Llama-3.1-70B-Instruct-GGUF
  llm_hf_model_file: Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf

embedding:
  mode: huggingface

huggingface:
  embedding_hf_model_name: nomic-ai/nomic-embed-text-v1.5

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant
